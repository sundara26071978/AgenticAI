{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROD MODELS\n",
    "distil-whisper-large-v3-en, gemma2-9b-it, llama-3.3-70b-versatile, llama-3.1-8b-instant, llama-guard-3-8b, llama3-70b-8192, llama3-8b-8192\n",
    "mixtral-8x7b-32768, whisper-large-v3,whisper-large-v3-turbo\n",
    "### PREVIEW MODELS\n",
    "deepseek-r1-distill-llama-70b, llama-3.3-70b-specdec, llama-3.2-1b-preview, llama-3.2-3b-preview, llama-3.2-11b-vision-preview, llama-3.2-90b-vision-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n",
    "# llm.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| color| of| the| sky| can| appear| different| depending| on| the| time| of| day|,| atmospheric| conditions|,| and| location|.| Here| are| some| common| answers|:\n",
      "\n",
      "|1|.| **|Blue|**:| During| the| daytime|,| when| the| sun| is| overhead|,| the| sky| typically| appears| a| shade| of| blue| to| our| eyes|.| This| is| because| the| Earth|'s| atmosphere| sc|atters| sunlight| in| all| directions|,| and| shorter| (|blue|)| wavelengths| are| scattered| more| than| longer| (|red|)| wavelengths|,| giving| the| sky| its| blue| color|.\n",
      "|2|.| **|Golden|/H|oney|**:| During| sunrise| and| sunset|,| the| sky| can| take| on| hues| of| gold|,| orange|,| pink|,| and| red|.| This| is| due| to| the| scattering| of| light| by| atmospheric| particles|,| which| favors| longer| wavelengths| like| red| and| orange|.\n",
      "|3|.| **|Gray|**:| On| over|cast| days|,| the| sky| can| appear| a| dull| gray| or| white|,| as| the| sunlight| is| scattered| in| all| directions| by| the| cloud| cover|.\n",
      "|4|.| **|Black|**:| At| night|,| the| sky| can| appear| black|,| although| it| can| still| be| illuminated| by| moon|light|,| star|light|,| or| artificial| light| pollution|.\n",
      "|5|.| **|Other| colors|**:| Depending| on| the| location| and| atmospheric| conditions|,| the| sky| can| also| appear|:\n",
      "|\t|*| Green|ish| during| severe| thunder|storms| or| dust| storms|.\n",
      "|\t|*| Yellow|ish| or| brown|ish| due| to| dust|,| smoke|,| or| pollution|.\n",
      "|\t|*| Purple| or| redd|ish| during| intense| dust| storms| or| volcanic| eru|ptions|.\n",
      "|\t|*| Pink| or| redd|ish| during| certain| types| of| aur|or|ae| (|nor|thern| or| southern| lights|).\n",
      "\n",
      "|So|,| to| answer| your| question|,| the| color| of| the| sky| is|...| complex|!| It| depends| on| the| time| of| day|,| weather|,| and| location|.||"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for chunk in model.stream(\"what color is the sky?\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-c554bf24-9d9c-457b-bf64-11eab5601110')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|What| a| great| question|!\n",
      "\n",
      "|The| answer| is| not| a| simple| one|,| as| it| depends| on| the| time| of| day|,| atmospheric| conditions|,| and| the| observer|'s| location|.| Here| are| some| different| answers|:\n",
      "\n",
      "|1|.| **|During| the| day|**:| When| the| sun| is| overhead|,| the| sky| appears| blue| to| our| eyes| because| of| a| phenomenon| called| Ray|leigh| scattering|.| This| is| when| shorter| (|blue|)| wavelengths| of| light| are| scattered| more| than| longer| (|red|)| wavelengths| by| the| tiny| molecules| of| gases| in| the| atmosphere|,| such| as| nitrogen| and| oxygen|.| This| scattering| effect| gives| the| sky| its| blue| color|.\n",
      "|2|.| **|At| sunrise| and| sunset|**:| During| these| times|,| the| sun| is| lower| in| the| sky|,| and| the| light| it| emits| has| to| travel| longer| distances| through| the| atmosphere|.| As| a| result|,| much| of| the| shorter| wavelength| blue| light| is| scattered| away|,| leaving| mainly| longer| wavelength| red| and| orange| light| to| reach| our| eyes|.| This| is| why| the| sky| often| appears| more| red| or| orange| during| sunrise| and| sunset|.\n",
      "|3|.| **|At| night|**:| When| the| sun| is| below| the| horizon|,| the| sky| can| appear| dark|,| but| it|'s| not| actually| black|.| The| atmosphere| still| sc|atters| some| light| from| the| stars| and| other| celestial| objects|,| making| the| sky| appear| a| deep| shade| of| blue| or| ind|igo|.| This| is| known| as| the| \"|night| sky| glow|.\"\n",
      "|4|.| **|In| other| conditions|**:| The| color| of| the| sky| can| also| be| affected| by| pollution|,| dust|,| and| water| vapor| in| the| atmosphere|,| which| can| scatter| light| in| different| ways| and| change| its| apparent| color|.| For| example|,| during| severe| dust| storms| or| wildfires|,| the| sky| can| take| on| a| h|azy|,| orange| or| redd|ish| hue|.\n",
      "\n",
      "|So|,| to| summarize|,| the| color| of| the| sky| is| not| always| the| same|,| and| it| can| change| depending| on| the| time| of| day|,| atmospheric| conditions|,| and| location|.| But| in| general|,| the| sky| appears| blue| during| the| day|,| and| more| red| or| orange| during| sunrise| and| sunset|.||"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "async for chunk in model.astream(\"what color is the sky?\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='What', additional_kwargs={}, response_metadata={}, id='run-5fff3a6d-ea9f-4ef8-ae4b-2995310e5186')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='What a great question', additional_kwargs={}, response_metadata={}, id='run-5fff3a6d-ea9f-4ef8-ae4b-2995310e5186')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0] + chunks[1] + chunks[2] + chunks[3] + chunks[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain using Langchain expression language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Why| did| the| par|rot| go| to| the| doctor|?\n",
      "\n",
      "|Because| it| had| a| f|owl| cough|!||"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "\n",
    "model = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "async for chunk in chain.astream({\"topic\": \"parrot\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Input Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': ''}]}\n",
      "{'countries': [{'name': 'France'}]}\n",
      "{'countries': [{'name': 'France', 'population': 652}]}\n",
      "{'countries': [{'name': 'France', 'population': 652735}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain'}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain', 'population': 467}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain', 'population': 467547}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain', 'population': 46754713}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain', 'population': 46754713}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain', 'population': 46754713}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain', 'population': 46754713}, {'name': 'Japan'}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain', 'population': 46754713}, {'name': 'Japan', 'population': 128}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain', 'population': 46754713}, {'name': 'Japan', 'population': 128000}]}\n",
      "{'countries': [{'name': 'France', 'population': 65273539}, {'name': 'Spain', 'population': 46754713}, {'name': 'Japan', 'population': 128000000}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")  # Due to a bug in older versions of Langchain, JsonOutputParser did not stream results from some models\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\"\n",
    "):\n",
    "    print(text, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']|"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import (\n",
    "    JsonOutputParser,\n",
    ")\n",
    "\n",
    "\n",
    "# A function that operates on finalized inputs\n",
    "# rather than on an input_stream\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = model | JsonOutputParser() |  _extract_country_names\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\"\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France|Spain|Japan|"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "async def _extract_country_names_streaming(input_stream):\n",
    "    \"\"\"A function that operates on input streams.\"\"\"\n",
    "    country_names_so_far = set()\n",
    "\n",
    "    async for input in input_stream:\n",
    "        if not isinstance(input, dict):\n",
    "            continue\n",
    "\n",
    "        if \"countries\" not in input:\n",
    "            continue\n",
    "\n",
    "        countries = input[\"countries\"]\n",
    "\n",
    "        if not isinstance(countries, list):\n",
    "            continue\n",
    "\n",
    "        for country in countries:\n",
    "            name = country.get(\"name\")\n",
    "            if not name:\n",
    "                continue\n",
    "            if name not in country_names_so_far:\n",
    "                yield name\n",
    "                country_names_so_far.add(name)\n",
    "\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names_streaming\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss-cpu\n",
    "#! pip install langchain_community\n",
    "#! pip install langchain_openai\n",
    "#! pip install langchain_huggingface\n",
    "#! pip install -U sentence-transformers\n",
    "#! pip install faiss-cpu\n",
    "# ! pip install langchain_openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|According| to| the| context|,| Harrison| worked| at| Kens|ho|.\n",
      "\n",
      "|Here| are| three| made|-up| sentences| about| Kens|ho|:\n",
      "\n",
      "|K|ens|ho| is| a| trendy| startup| located| in| the| heart| of| Silicon| Valley|,| specializing| in| AI|-powered| analytics|.| The| office| space| features| a| rooftop| garden| where| employees| can| relax| and| enjoy| the| views| of| the| surrounding| city|scape|.| Kens|ho|'s| state|-of|-the|-art| facilities| are| equipped| with| the| latest| technology|,| making| it| an| ideal| workplace| for| innov|ators| and| thinkers| like| Harrison|.||"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\", \"harrison likes spicy food\"],\n",
    "    embedding=embeddings_model,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# chunks = [chunk for chunk in retriever.stream(\"where did harrison work?\")]\n",
    "# chunks\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "for chunk in retrieval_chain.stream(\n",
    "    \"Where did harrison work? \" \"Write 3 made up sentences about this place.\"\n",
    "):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "async for event in model.astream_events(\"hello\", version=\"v2\"):\n",
    "    events.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event': 'on_chat_model_end',\n",
       " 'data': {'output': AIMessageChunk(content=\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\", additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run-eccd533c-8769-4119-9fa0-a69b88676bbd', usage_metadata={'input_tokens': 11, 'output_tokens': 26, 'total_tokens': 37})},\n",
       " 'run_id': 'eccd533c-8769-4119-9fa0-a69b88676bbd',\n",
       " 'name': 'ChatGroq',\n",
       " 'tags': [],\n",
       " 'metadata': {'ls_provider': 'groq',\n",
       "  'ls_model_name': 'llama3-8b-8192',\n",
       "  'ls_model_type': 'chat',\n",
       "  'ls_temperature': 0.7},\n",
       " 'parent_ids': []}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")  # Due to a bug in older versions of Langchain, JsonOutputParser did not stream results from some models\n",
    "\n",
    "events = [\n",
    "    event\n",
    "    async for event in chain.astream_events(\n",
    "        \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "        'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "        \"Each country should have the key `name` and `population`\",\n",
    "        version=\"v2\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: 'Here'\n",
      "Chat model chunk: ' is'\n",
      "Chat model chunk: ' the'\n",
      "Chat model chunk: ' JSON'\n",
      "Chat model chunk: ' output'\n",
      "Chat model chunk: ':\\n'\n",
      "Chat model chunk: '``'\n",
      "Chat model chunk: '`\\n'\n",
      "Chat model chunk: '{\\n'\n",
      "Parser chunk: {}\n",
      "Chat model chunk: ' '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'countries'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' [\\n'\n",
      "Parser chunk: {'countries': []}\n",
      "Chat model chunk: '   '\n",
      "Chat model chunk: ' {\\n'\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Chat model chunk: '     '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'name'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' \"'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "num_events = 0\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "    version=\"v2\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"Parser chunk: {event['data']['chunk']}\", flush=True)\n",
    "    num_events += 1\n",
    "    if num_events > 30:\n",
    "        # Truncate the output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_parser_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'my_parser', 'tags': ['seq:step:2'], 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'metadata': {}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': []}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{}]}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': ''}]}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France'}]}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 670}]}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 670000}]}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67000000}]}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67000000}, {}]}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "{'event': 'on_parser_stream', 'run_id': '230389e0-9d88-40ab-bee1-6070052eab6e', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67000000}, {'name': ''}]}}, 'parent_ids': ['9df8052b-7bdc-406c-9245-9f23afee4f97']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "    {\"run_name\": \"my_parser\"}\n",
    ")\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "    version=\"v2\",\n",
    "    include_names=[\"my_parser\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # Truncate output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chat_model_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'model', 'tags': ['seq:step:1'], 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='Here', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' output', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' JSON', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' format', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=':\\n', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='``', additional_kwargs={}, response_metadata={}, id='run-1e3a4d13-6c4a-495e-bc70-96c03547362d')}, 'run_id': '1e3a4d13-6c4a-495e-bc70-96c03547362d', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['faa9e968-f78c-44e6-8001-7eec291e0255']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "    {\"run_name\": \"my_parser\"}\n",
    ")\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`',\n",
    "    version=\"v2\",\n",
    "    include_types=[\"chat_model\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # Truncate output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'RunnableSequence', 'tags': ['my_chain'], 'run_id': '129ee5e1-dfb8-4c6b-a46d-cb782ccb2037', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`', additional_kwargs={}, response_metadata={})]]}}, 'name': 'ChatGroq', 'tags': ['seq:step:1', 'my_chain'], 'run_id': '3d6b80fb-53ba-47ab-bf91-1d198850ee18', 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-3d6b80fb-53ba-47ab-bf91-1d198850ee18')}, 'run_id': '3d6b80fb-53ba-47ab-bf91-1d198850ee18', 'name': 'ChatGroq', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "{'event': 'on_parser_start', 'data': {}, 'name': 'JsonOutputParser', 'tags': ['seq:step:2', 'my_chain'], 'run_id': 'ad597647-4511-4f1b-adcb-8f1040a67997', 'metadata': {}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='Here', additional_kwargs={}, response_metadata={}, id='run-3d6b80fb-53ba-47ab-bf91-1d198850ee18')}, 'run_id': '3d6b80fb-53ba-47ab-bf91-1d198850ee18', 'name': 'ChatGroq', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-3d6b80fb-53ba-47ab-bf91-1d198850ee18')}, 'run_id': '3d6b80fb-53ba-47ab-bf91-1d198850ee18', 'name': 'ChatGroq', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-3d6b80fb-53ba-47ab-bf91-1d198850ee18')}, 'run_id': '3d6b80fb-53ba-47ab-bf91-1d198850ee18', 'name': 'ChatGroq', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' output', additional_kwargs={}, response_metadata={}, id='run-3d6b80fb-53ba-47ab-bf91-1d198850ee18')}, 'run_id': '3d6b80fb-53ba-47ab-bf91-1d198850ee18', 'name': 'ChatGroq', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-3d6b80fb-53ba-47ab-bf91-1d198850ee18')}, 'run_id': '3d6b80fb-53ba-47ab-bf91-1d198850ee18', 'name': 'ChatGroq', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=' requested', additional_kwargs={}, response_metadata={}, id='run-3d6b80fb-53ba-47ab-bf91-1d198850ee18')}, 'run_id': '3d6b80fb-53ba-47ab-bf91-1d198850ee18', 'name': 'ChatGroq', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content=':\\n', additional_kwargs={}, response_metadata={}, id='run-3d6b80fb-53ba-47ab-bf91-1d198850ee18')}, 'run_id': '3d6b80fb-53ba-47ab-bf91-1d198850ee18', 'name': 'ChatGroq', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'groq', 'ls_model_name': 'llama3-8b-8192', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['129ee5e1-dfb8-4c6b-a46d-cb782ccb2037']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "chain = (model | JsonOutputParser()).with_config({\"tags\": [\"my_chain\"]})\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`',\n",
    "    version=\"v2\",\n",
    "    include_tags=[\"my_chain\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # Truncate output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that does not support streaming.\n",
    "# It operates on the finalizes inputs rather than\n",
    "# operating on the input stream.\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser() | _extract_country_names\n",
    ")  # This parser only works with OpenAI right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']\n"
     ]
    }
   ],
   "source": [
    "async for chunk in chain.astream(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "):\n",
    "    print(chunk, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: 'Here'\n",
      "Chat model chunk: ' is'\n",
      "Chat model chunk: ' the'\n",
      "Chat model chunk: ' JSON'\n",
      "Chat model chunk: ' output'\n",
      "Chat model chunk: ' you'\n",
      "Chat model chunk: ' requested'\n",
      "Chat model chunk: ':\\n'\n",
      "Chat model chunk: '``'\n",
      "Chat model chunk: '`\\n'\n",
      "Chat model chunk: '{\\n'\n",
      "Parser chunk: {}\n",
      "Chat model chunk: ' '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'countries'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' [\\n'\n",
      "Parser chunk: {'countries': []}\n",
      "Chat model chunk: '   '\n",
      "Chat model chunk: ' {\\n'\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Chat model chunk: '     '\n",
      "Chat model chunk: ' \"'\n",
      "Chat model chunk: 'name'\n",
      "Chat model chunk: '\":'\n",
      "Chat model chunk: ' \"'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "num_events = 0\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "    \"output a list of the countries france, spain and japan and their populations in JSON format. \"\n",
    "    'Use a dict with an outer key of \"countries\" which contains a list of countries. '\n",
    "    \"Each country should have the key `name` and `population`\",\n",
    "    version=\"v2\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"Parser chunk: {event['data']['chunk']}\", flush=True)\n",
    "    num_events += 1\n",
    "    if num_events > 30:\n",
    "        # Truncate the output\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'bad_tool', 'tags': [], 'run_id': '83c3ff86-327a-4e6c-adb9-86415db44b77', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': 'f58aaf10-507f-4d9f-bf3a-69efdb1f4825', 'metadata': {}, 'parent_ids': ['83c3ff86-327a-4e6c-adb9-86415db44b77']}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': 'f58aaf10-507f-4d9f-bf3a-69efdb1f4825', 'name': 'reverse_word', 'tags': [], 'metadata': {}, 'parent_ids': ['83c3ff86-327a-4e6c-adb9-86415db44b77']}\n",
      "{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': '83c3ff86-327a-4e6c-adb9-86415db44b77', 'name': 'bad_tool', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "def reverse_word(word: str):\n",
    "    return word[::-1]\n",
    "\n",
    "\n",
    "reverse_word = RunnableLambda(reverse_word)\n",
    "\n",
    "\n",
    "@tool\n",
    "def bad_tool(word: str):\n",
    "    \"\"\"Custom tool that doesn't propagate callbacks.\"\"\"\n",
    "    return reverse_word.invoke(word)\n",
    "\n",
    "\n",
    "async for event in bad_tool.astream_events(\"hello\", version=\"v2\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'correct_tool', 'tags': [], 'run_id': 'a61cce1f-c0f6-4d90-a438-121b7b7ae765', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': 'c926aa0a-85b9-4da2-874c-bc32a83dbd18', 'metadata': {}, 'parent_ids': ['a61cce1f-c0f6-4d90-a438-121b7b7ae765']}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': 'c926aa0a-85b9-4da2-874c-bc32a83dbd18', 'name': 'reverse_word', 'tags': [], 'metadata': {}, 'parent_ids': ['a61cce1f-c0f6-4d90-a438-121b7b7ae765']}\n",
      "{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': 'a61cce1f-c0f6-4d90-a438-121b7b7ae765', 'name': 'correct_tool', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def correct_tool(word: str, callbacks):\n",
    "    \"\"\"A tool that correctly propagates callbacks.\"\"\"\n",
    "    return reverse_word.invoke(word, {\"callbacks\": callbacks})\n",
    "\n",
    "\n",
    "async for event in correct_tool.astream_events(\"hello\", version=\"v2\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': '78621d92-0b6d-4815-9c1a-f3065d532666', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_stream', 'run_id': '78621d92-0b6d-4815-9c1a-f3065d532666', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'data': {'chunk': '43214321'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': '78621d92-0b6d-4815-9c1a-f3065d532666', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "async def reverse_and_double(word: str):\n",
    "    return await reverse_word.ainvoke(word) * 2\n",
    "\n",
    "\n",
    "reverse_and_double = RunnableLambda(reverse_and_double)\n",
    "\n",
    "await reverse_and_double.ainvoke(\"1234\")\n",
    "\n",
    "async for event in reverse_and_double.astream_events(\"1234\", version=\"v2\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': '3ebbf4f1-8fe7-4fac-a03c-6a44abac63de', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chain_stream', 'run_id': '3ebbf4f1-8fe7-4fac-a03c-6a44abac63de', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'data': {'chunk': '43214321'}, 'parent_ids': []}\n",
      "{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': '3ebbf4f1-8fe7-4fac-a03c-6a44abac63de', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "async def reverse_and_double(word: str):\n",
    "    return await reverse_word.ainvoke(word) * 2\n",
    "\n",
    "\n",
    "await reverse_and_double.ainvoke(\"1234\")\n",
    "\n",
    "async for event in reverse_and_double.astream_events(\"1234\", version=\"v2\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310finrobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
